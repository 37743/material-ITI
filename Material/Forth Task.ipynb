{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8dd97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c05141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>335</td>\n",
       "      <td>336</td>\n",
       "      <td>2011-01-15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>18</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7035</td>\n",
       "      <td>7036</td>\n",
       "      <td>2011-10-25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>65</td>\n",
       "      <td>453</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8051</td>\n",
       "      <td>8052</td>\n",
       "      <td>2011-12-07</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2133</td>\n",
       "      <td>2134</td>\n",
       "      <td>2011-04-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>71</td>\n",
       "      <td>101</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8485</td>\n",
       "      <td>8486</td>\n",
       "      <td>2011-12-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n",
       "0         335      336  2011-01-15       1   0     1  11        0        6   \n",
       "1        7035     7036  2011-10-25       4   0    10  18        0        2   \n",
       "2        8051     8052  2011-12-07       4   0    12   3        0        3   \n",
       "3        2133     2134  2011-04-03       2   0     4  18        0        0   \n",
       "4        8485     8486  2011-12-25       1   0    12   6        0        0   \n",
       "\n",
       "   workingday  weathersit  temp   atemp   hum  windspeed  casual  registered  \\\n",
       "0           0           1  0.20  0.1970  0.55     0.2239      18          54   \n",
       "1           1           1  0.52  0.5000  0.42     0.1045      65         453   \n",
       "2           1           3  0.46  0.4545  1.00     0.2239       0           3   \n",
       "3           0           2  0.46  0.4545  0.31     0.0000      71         101   \n",
       "4           0           1  0.20  0.2273  0.75     0.1045       0           1   \n",
       "\n",
       "   cnt  \n",
       "0   72  \n",
       "1  518  \n",
       "2    3  \n",
       "3  172  \n",
       "4    1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train_reg.csv\")\n",
    "test_data = pd.read_csv(\"x_test_reg.csv\")\n",
    "test_data['cnt'] = test_data['casual'] + test_data['registered']\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c726698",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12830</td>\n",
       "      <td>12831</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8688</td>\n",
       "      <td>8689</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7091</td>\n",
       "      <td>7092</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12230</td>\n",
       "      <td>12231</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.3582</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>431</td>\n",
       "      <td>432</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.3881</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  instant  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0       12830    12831       3   1     6  19        0        6           0   \n",
       "1        8688     8689       1   1     1  20        1        1           0   \n",
       "2        7091     7092       4   0    10   2        0        5           1   \n",
       "3       12230    12231       2   1     5  19        0        2           1   \n",
       "4         431      432       1   0     1   0        0        4           1   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  cnt  \n",
       "0           1  0.80  0.6970  0.27     0.1940  425  \n",
       "1           1  0.24  0.2273  0.41     0.2239   88  \n",
       "2           1  0.32  0.3030  0.66     0.2836    4  \n",
       "3           1  0.78  0.7121  0.52     0.3582  526  \n",
       "4           1  0.26  0.2273  0.56     0.3881   13  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.drop(['casual', 'registered', 'dteday'], axis = 1)\n",
    "test_data = test_data.drop(['casual', 'registered', 'dteday'], axis = 1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c75775",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d134740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38807197035692387"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop('cnt', axis=1)\n",
    "y_train = train_data['cnt']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = test_data.drop('cnt', axis=1)  # Features\n",
    "y_test = test_data['cnt'] # Target variable\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6985935b",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92dad7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5406174567643415"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop('cnt', axis=1)\n",
    "y_train = train_data['cnt']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "degree = 2  # Set the degree of the polynomial\n",
    "poly = PolynomialFeatures(degree)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_val_poly = poly.transform(X_val)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "X_test = test_data.drop('cnt', axis=1)\n",
    "y_test = test_data['cnt']\n",
    "\n",
    "X_test_poly = poly.transform(X_test)\n",
    "y_pred = model.predict(X_test_poly)\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b729418",
   "metadata": {},
   "source": [
    "# Huber Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fb0a339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2615278454567055"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop('cnt', axis=1)\n",
    "y_train = train_data['cnt']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "model = HuberRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = test_data.drop('cnt', axis=1)\n",
    "y_test = test_data['cnt']\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12cc7e3",
   "metadata": {},
   "source": [
    "# ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fcad156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35028922116817807"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop('cnt', axis=1)\n",
    "y_train = train_data['cnt']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "alpha = 0.1  # Regularization strength\n",
    "l1_ratio = 0.5  # Mix of L1 and L2 regularization\n",
    "\n",
    "model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = test_data.drop('cnt', axis=1)\n",
    "y_test = test_data['cnt']\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b5ea3",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13a633f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3755574629122146"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop('cnt', axis=1).values\n",
    "y_train = train_data['cnt'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "n_neighbors = 5  # Number of neighbors\n",
    "model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = test_data.drop('cnt', axis=1).values\n",
    "y_test = test_data['cnt'].values\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba5d0e",
   "metadata": {},
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4940491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04097772129870336"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop('cnt', axis=1).values\n",
    "y_train = train_data['cnt'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "model = SVR(kernel='rbf')  # Radial basis function (RBF) kernel\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = test_data.drop('cnt', axis=1).values\n",
    "y_test = test_data['cnt'].values\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1246fd",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e37429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8658527333923105"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop('cnt', axis=1)\n",
    "y_train = train_data['cnt']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = test_data.drop('cnt', axis=1).values\n",
    "y_test = test_data['cnt'].values\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240bbfe",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5898aa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8991022627029014"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop('cnt', axis=1)\n",
    "y_train = train_data['cnt']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = test_data.drop('cnt', axis=1).values\n",
    "y_test = test_data['cnt'].values\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7706636a",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "785da5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9463200623351025"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop('cnt', axis=1)\n",
    "y_train = train_data['cnt']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = test_data.drop('cnt', axis=1).values\n",
    "y_test = test_data['cnt'].values\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce53426",
   "metadata": {},
   "source": [
    "# Neural Network Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ccd2fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "348/348 [==============================] - 2s 3ms/step - loss: 61075.7188 - val_loss: 31463.2402\n",
      "Epoch 2/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 32213.8750 - val_loss: 29720.5156\n",
      "Epoch 3/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 30821.0312 - val_loss: 28269.8652\n",
      "Epoch 4/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 30020.4199 - val_loss: 32684.0273\n",
      "Epoch 5/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 29354.1973 - val_loss: 26369.7285\n",
      "Epoch 6/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 27733.3945 - val_loss: 30579.0781\n",
      "Epoch 7/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 28419.3086 - val_loss: 25429.5605\n",
      "Epoch 8/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 28212.9668 - val_loss: 26509.7793\n",
      "Epoch 9/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 27205.6992 - val_loss: 25552.7539\n",
      "Epoch 10/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 27416.4707 - val_loss: 28950.6504\n",
      "Epoch 11/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 26463.3418 - val_loss: 24731.1562\n",
      "Epoch 12/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 27357.3066 - val_loss: 26483.7168\n",
      "Epoch 13/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 26810.7461 - val_loss: 25176.9316\n",
      "Epoch 14/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 26650.4844 - val_loss: 32813.9531\n",
      "Epoch 15/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 26108.7949 - val_loss: 24168.0918\n",
      "Epoch 16/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 26297.2578 - val_loss: 26987.2969\n",
      "Epoch 17/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 27460.4141 - val_loss: 24847.6484\n",
      "Epoch 18/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25706.2949 - val_loss: 27402.8105\n",
      "Epoch 19/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 27153.9355 - val_loss: 23769.6016\n",
      "Epoch 20/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 26549.8086 - val_loss: 27647.8906\n",
      "Epoch 21/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25693.4277 - val_loss: 23544.1836\n",
      "Epoch 22/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25588.1777 - val_loss: 23497.9707\n",
      "Epoch 23/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25234.4453 - val_loss: 24027.4258\n",
      "Epoch 24/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25259.5527 - val_loss: 25468.3730\n",
      "Epoch 25/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25205.5625 - val_loss: 38287.5078\n",
      "Epoch 26/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25610.0215 - val_loss: 24793.5898\n",
      "Epoch 27/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25162.4785 - val_loss: 29745.8262\n",
      "Epoch 28/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25281.9590 - val_loss: 23312.5273\n",
      "Epoch 29/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25471.1504 - val_loss: 23715.0137\n",
      "Epoch 30/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25854.7168 - val_loss: 26673.1602\n",
      "Epoch 31/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25324.6289 - val_loss: 23005.2285\n",
      "Epoch 32/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25653.9121 - val_loss: 26630.4688\n",
      "Epoch 33/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25333.1406 - val_loss: 23160.4375\n",
      "Epoch 34/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25448.6602 - val_loss: 26165.4883\n",
      "Epoch 35/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24577.1992 - val_loss: 23836.7676\n",
      "Epoch 36/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25002.4160 - val_loss: 23967.7051\n",
      "Epoch 37/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24579.9023 - val_loss: 24732.6309\n",
      "Epoch 38/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24899.2461 - val_loss: 23272.9453\n",
      "Epoch 39/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24501.4863 - val_loss: 25822.4688\n",
      "Epoch 40/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24681.9922 - val_loss: 24830.9668\n",
      "Epoch 41/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24754.2383 - val_loss: 33211.9688\n",
      "Epoch 42/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25196.7578 - val_loss: 22751.2344\n",
      "Epoch 43/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25678.3047 - val_loss: 23202.8457\n",
      "Epoch 44/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25455.6250 - val_loss: 24099.3633\n",
      "Epoch 45/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24730.5039 - val_loss: 23951.3730\n",
      "Epoch 46/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24588.0059 - val_loss: 24755.3516\n",
      "Epoch 47/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24273.8730 - val_loss: 24812.9141\n",
      "Epoch 48/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24323.1816 - val_loss: 22823.4199\n",
      "Epoch 49/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25588.5117 - val_loss: 24795.6621\n",
      "Epoch 50/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24496.3027 - val_loss: 24075.4395\n",
      "Epoch 51/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24403.5312 - val_loss: 23081.0293\n",
      "Epoch 52/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25262.7188 - val_loss: 26545.8691\n",
      "Epoch 53/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25474.6836 - val_loss: 22837.0098\n",
      "Epoch 54/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24579.8633 - val_loss: 22784.9570\n",
      "Epoch 55/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24543.7148 - val_loss: 22500.6016\n",
      "Epoch 56/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25012.3965 - val_loss: 23201.3203\n",
      "Epoch 57/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24209.2266 - val_loss: 24086.7441\n",
      "Epoch 58/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24783.5742 - val_loss: 22462.8008\n",
      "Epoch 59/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24001.3887 - val_loss: 22852.7363\n",
      "Epoch 60/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24020.5879 - val_loss: 28644.8320\n",
      "Epoch 61/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24717.1602 - val_loss: 23570.9277\n",
      "Epoch 62/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24454.7676 - val_loss: 23827.9434\n",
      "Epoch 63/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23998.9492 - val_loss: 22371.0430\n",
      "Epoch 64/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24005.2676 - val_loss: 22268.3203\n",
      "Epoch 65/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24772.1348 - val_loss: 22289.3301\n",
      "Epoch 66/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23981.0527 - val_loss: 23723.8223\n",
      "Epoch 67/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24021.1816 - val_loss: 25268.5762\n",
      "Epoch 68/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24785.0879 - val_loss: 22523.6758\n",
      "Epoch 69/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23964.7812 - val_loss: 22198.9277\n",
      "Epoch 70/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24080.8281 - val_loss: 23116.4844\n",
      "Epoch 71/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24303.4238 - val_loss: 22230.8926\n",
      "Epoch 72/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23300.7051 - val_loss: 22173.1543\n",
      "Epoch 73/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24639.0508 - val_loss: 23818.7031\n",
      "Epoch 74/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23843.6973 - val_loss: 22494.5527\n",
      "Epoch 75/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24628.8574 - val_loss: 22111.5449\n",
      "Epoch 76/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23654.5391 - val_loss: 23503.5820\n",
      "Epoch 77/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23863.4414 - val_loss: 24146.2207\n",
      "Epoch 78/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 25713.6035 - val_loss: 22205.6504\n",
      "Epoch 79/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24007.4863 - val_loss: 25687.5391\n",
      "Epoch 80/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23902.5645 - val_loss: 22755.5625\n",
      "Epoch 81/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23612.1172 - val_loss: 27867.6562\n",
      "Epoch 82/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24235.8477 - val_loss: 23029.5586\n",
      "Epoch 83/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24143.5742 - val_loss: 25592.7246\n",
      "Epoch 84/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23780.8359 - val_loss: 22807.1035\n",
      "Epoch 85/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23309.3418 - val_loss: 22209.2520\n",
      "Epoch 86/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24066.6621 - val_loss: 22959.8828\n",
      "Epoch 87/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24306.7246 - val_loss: 27175.8672\n",
      "Epoch 88/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23254.9180 - val_loss: 24095.2969\n",
      "Epoch 89/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24104.0938 - val_loss: 22712.1426\n",
      "Epoch 90/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23155.1582 - val_loss: 33099.2500\n",
      "Epoch 91/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23703.7598 - val_loss: 24773.7109\n",
      "Epoch 92/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23331.6074 - val_loss: 21810.9961\n",
      "Epoch 93/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23566.2891 - val_loss: 22122.3652\n",
      "Epoch 94/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23419.2402 - val_loss: 23631.3379\n",
      "Epoch 95/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23408.2832 - val_loss: 21816.5684\n",
      "Epoch 96/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23297.7090 - val_loss: 30206.7031\n",
      "Epoch 97/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 24433.4336 - val_loss: 27884.0566\n",
      "Epoch 98/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23342.6055 - val_loss: 22800.5781\n",
      "Epoch 99/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23383.5391 - val_loss: 22580.6484\n",
      "Epoch 100/100\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 23138.4160 - val_loss: 25212.0996\n",
      "109/109 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19497961566689037"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop('cnt', axis=1).values\n",
    "y_train = train_data['cnt'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "num_features = X_train.shape[1] \n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(num_features,)),  # Input layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer(s)\n",
    "    tf.keras.layers.Dense(1)  # Output layer (1 neuron for regression)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "X_test = test_data.drop('cnt', axis=1).values\n",
    "y_test = test_data['cnt'].values\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f66283",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1731f8b",
   "metadata": {},
   "source": [
    "### The best regression model is Random Forest Regression with accuracy 94 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa536ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
